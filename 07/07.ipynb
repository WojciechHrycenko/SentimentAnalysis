{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c634e73",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; text-align:center; font-family:Arial, Helvetica, sans-serif; padding:50px;\">\n",
    "  <!-- Tytuł -->\n",
    "  <div style=\"color:#993520; font-size:60px; font-weight:bold; margin-bottom:20px;\">\n",
    "    SENTIMENT ANALYSIS\n",
    "  </div>\n",
    "\n",
    "  <!-- Podtytuł -->\n",
    "  <div style=\"color:#993520; font-size:35px; margin-bottom:40px;\">\n",
    "    Supervised sentiment analysis: regression, binary & multiclass classification\n",
    "  </div>\n",
    "\n",
    "  <!-- Autor -->\n",
    "  <div style=\"color:black; font-size:30px; margin-bottom:10px;\">\n",
    "    Maciej Świtała, PhD\n",
    "  </div>\n",
    "\n",
    "  <!-- Data / semestr -->\n",
    "  <div style=\"color:black; font-size:30px; margin-bottom:50px;\">\n",
    "    Autumn 2025\n",
    "  </div>\n",
    "\n",
    "  <!-- Logo -->\n",
    "  <div>\n",
    "    <img src=\"img/wne-logo-new-en.jpg\" alt=\"WNE Logo\" style=\"max-width:400px; height:auto;\">\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc24142",
   "metadata": {},
   "source": [
    "### 1. Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50895ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy matplotlib nltk scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7297f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # for working with data in DataFrames\n",
    "import numpy as np  # numerical operations and arrays\n",
    "\n",
    "import matplotlib.pyplot as plt  # data visualization\n",
    "\n",
    "import pickle  # data loading\n",
    "import math  # mathematical functions\n",
    "import ast\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from collections import Counter  # counting occurrences of elements\n",
    "from itertools import islice\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer # VADER algorithm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e46a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/regression_model_data.pkl\", \"rb\") as f:\n",
    "    regression_model_data = pickle.load(f)\n",
    "\n",
    "X_train_regression = regression_model_data['X_train']\n",
    "X_test_regression = regression_model_data['X_test']\n",
    "y_train_regression = regression_model_data['y_train']\n",
    "y_test_regression = regression_model_data['y_test']\n",
    "\n",
    "with open(\"data/binary_classification_model_data.pkl\", \"rb\") as f:\n",
    "    binary_classification_model_data = pickle.load(f)\n",
    "\n",
    "X_train_binary_classification = binary_classification_model_data['X_train']\n",
    "X_test_binary_classification = binary_classification_model_data['X_test']\n",
    "y_train_binary_classification = binary_classification_model_data['y_train']\n",
    "y_test_binary_classification = binary_classification_model_data['y_test']\n",
    "\n",
    "with open(\"data/multinomial_classification_model_data.pkl\", \"rb\") as f:\n",
    "    multinomial_classification_model_data = pickle.load(f)\n",
    "\n",
    "X_train_multinomial_classification = multinomial_classification_model_data['X_train']\n",
    "X_test_multinomial_classification = multinomial_classification_model_data['X_test']\n",
    "y_train_multinomial_classification = multinomial_classification_model_data['y_train']\n",
    "y_test_multinomial_classification = multinomial_classification_model_data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a131b",
   "metadata": {},
   "source": [
    "### 2. Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a1bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models_comparison = []\n",
    "regression_models_comparison.append(['LASSO', 0.4294, 0.5275]) # see: previous materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c63acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV RMSE: 0.4474\n",
      "Test RMSE: 0.5624\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_regression, y_train_regression)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best CV RMSE:\", np.round(-grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred = grid.best_estimator_.predict(X_test_regression)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_regression, y_test_pred))\n",
    "print(\"Test RMSE:\", np.round(test_rmse,4))\n",
    "\n",
    "regression_models_comparison.append(['linear regression',np.round(-grid.best_score_,4), np.round(test_rmse,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330da268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'reg__n_neighbors': 7, 'reg__p': 2, 'reg__weights': 'distance'}\n",
      "Best CV RMSE: 0.4489\n",
      "Test RMSE: 0.5435\n"
     ]
    }
   ],
   "source": [
    "# pipeline: scale -> KNN\n",
    "pipeline = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"reg\", KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"reg__n_neighbors\": [3, 5, 7, 9, 11, 15, 20],\n",
    "    \"reg__weights\": [\"uniform\", \"distance\"],\n",
    "    \"reg__p\": [1, 2]   # 1 = Manhattan, 2 = Euclidean\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_train_regression, y_train_regression)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV RMSE:\", np.round(-grid.best_score_, 4))\n",
    "\n",
    "y_test_pred = grid.best_estimator_.predict(X_test_regression)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_regression, y_test_pred))\n",
    "print(\"Test RMSE:\", np.round(test_rmse, 4))\n",
    "\n",
    "regression_models_comparison.append(['KNN',np.round(-grid.best_score_,4), np.round(test_rmse,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80e8818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'reg__C': 1, 'reg__epsilon': 0.1, 'reg__gamma': 'scale', 'reg__kernel': 'rbf'}\n",
      "Best CV RMSE: 0.4345\n",
      "Test RMSE: 0.507\n"
     ]
    }
   ],
   "source": [
    "# pipeline: scale -> SVR\n",
    "pipeline = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"reg\", SVR())\n",
    "])\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"reg__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"reg__C\": [0.1, 1, 10],\n",
    "    \"reg__epsilon\": [0.01, 0.1, 1.0],\n",
    "    \"reg__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_train_regression, y_train_regression)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV RMSE:\", np.round(-grid.best_score_, 4))\n",
    "\n",
    "y_test_pred = grid.best_estimator_.predict(X_test_regression)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_regression, y_test_pred))\n",
    "print(\"Test RMSE:\", np.round(test_rmse, 4))\n",
    "\n",
    "regression_models_comparison.append(['SVR',np.round(-grid.best_score_,4), np.round(test_rmse,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3dc3158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best CV RMSE: 0.4776\n",
      "Test RMSE: 0.5492\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_regression, y_train_regression)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV RMSE:\", np.round(-grid.best_score_, 4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred = grid.best_estimator_.predict(X_test_regression)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_regression, y_test_pred))\n",
    "print(\"Test RMSE:\", np.round(test_rmse, 4))\n",
    "\n",
    "regression_models_comparison.append(['decision tree',np.round(-grid.best_score_,4), np.round(test_rmse,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22610466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best CV RMSE: 0.4394\n",
      "Test RMSE: 0.5375\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "reg = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_regression, y_train_regression)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV RMSE:\", np.round(-grid.best_score_, 4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred = grid.best_estimator_.predict(X_test_regression)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_regression, y_test_pred))\n",
    "print(\"Test RMSE:\", np.round(test_rmse, 4))\n",
    "\n",
    "regression_models_comparison.append(['random forest',np.round(-grid.best_score_,4), np.round(test_rmse,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32a2cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'colsample_bytree': 0.9, 'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Najlepszy RMSE CV: 0.4305\n",
      "RMSE testowe: 0.528\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "\n",
    "# parametry do optymalizacji\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [3, 5, 10, 20],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# dopasowanie modelu do zbioru treningowego\n",
    "grid.fit(X_train_regression, y_train_regression)\n",
    "\n",
    "# najlepsze parametry i wynik CV\n",
    "print(\"Najlepsze parametry:\", grid.best_params_)\n",
    "print(\"Najlepszy RMSE CV:\", np.round(-grid.best_score_, 4))\n",
    "\n",
    "# ocena na zbiorze testowym\n",
    "y_test_pred = grid.best_estimator_.predict(X_test_regression)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_regression, y_test_pred))\n",
    "print(\"RMSE testowe:\", np.round(test_rmse, 4))\n",
    "\n",
    "regression_models_comparison.append(['xgboost',np.round(-grid.best_score_,4), np.round(test_rmse,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d232a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse (cv)</th>\n",
       "      <th>rmse (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.4294</td>\n",
       "      <td>0.5275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.4305</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.4345</td>\n",
       "      <td>0.5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear regression</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.5624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.4489</td>\n",
       "      <td>0.5435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.5492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  rmse (cv)  rmse (test)\n",
       "0              LASSO     0.4294       0.5275\n",
       "6            xgboost     0.4305       0.5280\n",
       "3                SVR     0.4345       0.5070\n",
       "5      random forest     0.4394       0.5375\n",
       "1  linear regression     0.4474       0.5624\n",
       "2                KNN     0.4489       0.5435\n",
       "4      decision tree     0.4776       0.5492"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_models_comparison_df = pd.DataFrame(regression_models_comparison)\n",
    "regression_models_comparison_df.columns = ['model','rmse (cv)','rmse (test)']\n",
    "regression_models_comparison_df.sort_values(by='rmse (cv)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998a554",
   "metadata": {},
   "source": [
    "### 3. Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1734e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classification_models_comparison = []\n",
    "binary_classification_models_comparison.append(['LASSO', 0.8167, 0.6117]) # see: previous materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43257023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV ROC AUC: 0.8089\n",
      "Test ROC AUC: 0.6618\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# parameters to be optimised (przykład)\n",
    "param_grid = {}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_binary_classification, y_train_binary_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best CV ROC AUC:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_binary_classification)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test_binary_classification, y_test_pred_proba)\n",
    "print(\"Test ROC AUC:\", np.round(test_roc_auc,4))\n",
    "\n",
    "binary_classification_models_comparison.append(['logistic regression', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d53aff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__n_neighbors': 3, 'clf__p': 2, 'clf__weights': 'distance'}\n",
      "Best CV ROC AUC: 0.793\n",
      "Test ROC AUC: 0.5997\n"
     ]
    }
   ],
   "source": [
    "# pipeline: scale -> KNN\n",
    "pipeline = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"clf__n_neighbors\": [3, 5, 7, 9, 11, 15, 20],\n",
    "    \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "    \"clf__p\": [1, 2]   # 1 = Manhattan, 2 = Euclidean\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_train_binary_classification, y_train_binary_classification)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC:\", np.round(grid.best_score_, 4))\n",
    "\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_binary_classification)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test_binary_classification, y_test_pred_proba)\n",
    "print(\"Test ROC AUC:\", np.round(test_roc_auc,4))\n",
    "\n",
    "binary_classification_models_comparison.append(['KNN',np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10cc3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.1, 'clf__gamma': 'auto', 'clf__kernel': 'poly'}\n",
      "Best CV ROC AUC: 0.8968\n",
      "Test ROC AUC: 0.6558\n"
     ]
    }
   ],
   "source": [
    "# pipeline: scale -> SVC\n",
    "pipeline = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", SVC(probability=True))\n",
    "])\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"clf__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"clf__C\": [0.1, 1, 10],\n",
    "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_train_binary_classification, y_train_binary_classification)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC:\", np.round(grid.best_score_, 4))\n",
    "\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_binary_classification)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test_binary_classification, y_test_pred_proba)\n",
    "print(\"Test ROC AUC:\", np.round(test_roc_auc,4))\n",
    "\n",
    "binary_classification_models_comparison.append(['SVC',np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb0963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best CV ROC AUC: 0.6452\n",
      "Test ROC AUC: 0.5038\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_binary_classification, y_train_binary_classification)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC:\", np.round(grid.best_score_, 4))\n",
    "\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_binary_classification)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test_binary_classification, y_test_pred_proba)\n",
    "print(\"Test ROC AUC:\", np.round(test_roc_auc,4))\n",
    "\n",
    "binary_classification_models_comparison.append(['decision tree',np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db54a1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best CV ROC AUC: 0.8374\n",
      "Test ROC AUC: 0.6296\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_binary_classification, y_train_binary_classification)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC:\", np.round(grid.best_score_, 4))\n",
    "\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_binary_classification)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test_binary_classification, y_test_pred_proba)\n",
    "print(\"Test ROC AUC:\", np.round(test_roc_auc,4))\n",
    "\n",
    "binary_classification_models_comparison.append(['random forest',np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d85afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best CV ROC AUC: 0.6964\n",
      "Test ROC AUC: 0.6416\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42, n_jobs=-1)\n",
    "\n",
    "# parametry do optymalizacji\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [3, 5, 10, 20],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_binary_classification, y_train_binary_classification)\n",
    "\n",
    "# results\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC:\", np.round(grid.best_score_, 4))\n",
    "\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_binary_classification)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test_binary_classification, y_test_pred_proba)\n",
    "print(\"Test ROC AUC:\", np.round(test_roc_auc,4))\n",
    "\n",
    "binary_classification_models_comparison.append(['xgboost',np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631ad2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ROC AUC (cv)</th>\n",
       "      <th>ROC AUC (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.6558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>0.6296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.6618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.5997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.6416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.5038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  ROC AUC (cv)  ROC AUC (test)\n",
       "3                  SVC        0.8968          0.6558\n",
       "5        random forest        0.8374          0.6296\n",
       "0                LASSO        0.8167          0.6117\n",
       "1  logistic regression        0.8089          0.6618\n",
       "2                  KNN        0.7930          0.5997\n",
       "6              xgboost        0.6964          0.6416\n",
       "4        decision tree        0.6452          0.5038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_classification_models_comparison_df = pd.DataFrame(binary_classification_models_comparison)\n",
    "binary_classification_models_comparison_df.columns = ['model','ROC AUC (cv)','ROC AUC (test)']\n",
    "binary_classification_models_comparison_df.sort_values(by='ROC AUC (cv)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feadd8c",
   "metadata": {},
   "source": [
    "### 4. Multinomial classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a8f77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_classification_models_comparison = []\n",
    "multinomial_classification_models_comparison.append(['LASSO', 0.7041, 0.5469]) # see: previous materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7cffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV ROC AUC OVR: 0.6754\n",
      "Test ROC AUC OVR: 0.5969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\WNE\\studia magisterskie\\2025-26\\SENTIMENT ANALYSIS Autumn 2025\\07\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# parameters to be optimised (przykład)\n",
    "param_grid = {}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc_ovr',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_multinomial_classification, y_train_multinomial_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best CV ROC AUC OVR:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_multinomial_classification)\n",
    "test_roc_auc = roc_auc_score(y_test_multinomial_classification, y_test_pred_proba, multi_class='ovr')\n",
    "print(\"Test ROC AUC OVR:\", np.round(test_roc_auc,4))\n",
    "\n",
    "multinomial_classification_models_comparison.append(['logistic regression', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a84637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__n_neighbors': 20, 'clf__p': 2, 'clf__weights': 'distance'}\n",
      "Best CV ROC AUC OVR: 0.6527\n",
      "Test ROC AUC OVR: 0.5461\n"
     ]
    }
   ],
   "source": [
    "# pipeline: scale -> KNN\n",
    "pipeline = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"clf__n_neighbors\": [3, 5, 7, 9, 11, 15, 20],\n",
    "    \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "    \"clf__p\": [1, 2]   # 1 = Manhattan, 2 = Euclidean\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search (multiclass)\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc_ovr',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_multinomial_classification, y_train_multinomial_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC OVR:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_multinomial_classification)\n",
    "test_roc_auc = roc_auc_score(y_test_multinomial_classification, y_test_pred_proba, multi_class='ovr')\n",
    "print(\"Test ROC AUC OVR:\", np.round(test_roc_auc,4))\n",
    "\n",
    "multinomial_classification_models_comparison.append(['KNN', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a788424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n",
      "Best CV ROC AUC OVR: 0.7111\n",
      "Test ROC AUC OVR: 0.5827\n"
     ]
    }
   ],
   "source": [
    "# pipeline: scale -> SVC\n",
    "pipeline = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", SVC(probability=True))\n",
    "])\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"clf__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"clf__C\": [0.1, 1, 10],\n",
    "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc_ovr',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_multinomial_classification, y_train_multinomial_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC OVR:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_multinomial_classification)\n",
    "test_roc_auc = roc_auc_score(y_test_multinomial_classification, y_test_pred_proba, multi_class='ovr')\n",
    "print(\"Test ROC AUC OVR:\", np.round(test_roc_auc,4))\n",
    "\n",
    "multinomial_classification_models_comparison.append(['SVC', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9e8017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
      "Best CV ROC AUC OVR: 0.5977\n",
      "Test ROC AUC OVR: 0.4721\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc_ovr',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_multinomial_classification, y_train_multinomial_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC OVR:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_multinomial_classification)\n",
    "test_roc_auc = roc_auc_score(y_test_multinomial_classification, y_test_pred_proba, multi_class='ovr')\n",
    "print(\"Test ROC AUC OVR:\", np.round(test_roc_auc,4))\n",
    "\n",
    "multinomial_classification_models_comparison.append(['decision tree', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb31432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best CV ROC AUC OVR: 0.7073\n",
      "Test ROC AUC OVR: 0.5448\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# parameters to be optimised\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc_ovr',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_multinomial_classification, y_train_multinomial_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC OVR:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_multinomial_classification)\n",
    "test_roc_auc = roc_auc_score(y_test_multinomial_classification, y_test_pred_proba, multi_class='ovr')\n",
    "print(\"Test ROC AUC OVR:\", np.round(test_roc_auc,4))\n",
    "\n",
    "multinomial_classification_models_comparison.append(['random forest', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9cb4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.8, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best CV ROC AUC OVR: 0.6618\n",
      "Test ROC AUC OVR: 0.5551\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "clf = xgb.XGBClassifier(objective='multi:softprob', random_state=42, n_jobs=-1)\n",
    "\n",
    "# parametry do optymalizacji\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [3, 5, 10, 20],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc_ovr',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# target needs to take integer values starting from 1; the easiest way to convert it flexibly is: \n",
    "le = LabelEncoder()\n",
    "y_train_multinomial_classification = le.fit_transform(y_train_multinomial_classification)\n",
    "y_test_multinomial_classification = le.transform(y_test_multinomial_classification)\n",
    "\n",
    "# fit the model on the training set\n",
    "grid.fit(X_train_multinomial_classification, y_train_multinomial_classification)\n",
    "\n",
    "# print best hyperparameters and CV score\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV ROC AUC OVR:\", np.round(grid.best_score_,4))\n",
    "\n",
    "# evaluate on the test set\n",
    "y_test_pred_proba = grid.best_estimator_.predict_proba(X_test_multinomial_classification)\n",
    "test_roc_auc = roc_auc_score(y_test_multinomial_classification, y_test_pred_proba, multi_class='ovr')\n",
    "print(\"Test ROC AUC OVR:\", np.round(test_roc_auc,4))\n",
    "\n",
    "multinomial_classification_models_comparison.append(['xgboost', np.round(grid.best_score_,4), np.round(test_roc_auc,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc59abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ROC AUC OVR (cv)</th>\n",
       "      <th>ROC AUC OVR (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.5827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.5448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.6754</td>\n",
       "      <td>0.5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.6618</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.5461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.5977</td>\n",
       "      <td>0.4721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  ROC AUC OVR (cv)  ROC AUC OVR (test)\n",
       "3                  SVC            0.7111              0.5827\n",
       "5        random forest            0.7073              0.5448\n",
       "0                LASSO            0.7041              0.5469\n",
       "1  logistic regression            0.6754              0.5969\n",
       "6              xgboost            0.6618              0.5551\n",
       "2                  KNN            0.6527              0.5461\n",
       "4        decision tree            0.5977              0.4721"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_classification_models_comparison_df = pd.DataFrame(multinomial_classification_models_comparison)\n",
    "multinomial_classification_models_comparison_df.columns = ['model','ROC AUC OVR (cv)','ROC AUC OVR (test)']\n",
    "multinomial_classification_models_comparison_df.sort_values(by='ROC AUC OVR (cv)', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
